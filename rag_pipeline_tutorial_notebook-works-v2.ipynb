# -*- coding: utf-8 -*-
"""rag-pipeline-tutorial-notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JHwSOmyUnHOzMksNFBfr8nCt8vKLQDr_

<a href="https://colab.research.google.com/github/ruparee/rag-pipeline-tutorial-notebook/blob/main/rag-pipeline-tutorial-notebook.ipynb" target="_parent">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>
"""

# ‚úÖ Ensure all required packages are installed
!pip install --upgrade pinecone-client langchain-pinecone langchain sentence-transformers openai

import os
import subprocess

repo_url = "https://github.com/ruparee/rag-pipeline-tutorial.git"
repo_name = "rag-pipeline-tutorial"

# Check if the directory exists
if os.path.exists(repo_name):
    print(f"‚úÖ Directory '{repo_name}' already exists. Checking for updates...")
    os.chdir(repo_name)  # Move into the repo directory
    try:
        subprocess.run(["git", "pull", "origin", "main"], check=True)
        print("‚úÖ Repository updated successfully!")
    except subprocess.CalledProcessError as e:
        print(f"‚ö†Ô∏è Error pulling latest changes: {e}. Proceeding with existing files.")
    os.chdir("..")  # Move back to the original directory
else:
    print(f"‚úÖ Cloning repository '{repo_name}'...")
    subprocess.run(["git", "clone", repo_url], check=True)
    print("‚úÖ Repository cloned successfully!")

"""
# üîç **RAG Pipeline with Pinecone & Sentence Transformers**
This notebook implements a **Retrieval-Augmented Generation (RAG) pipeline** using:
- **Google Colab's Secure Secret Management** (`userdata.get()`)
- **Pinecone for vector storage**
- **`sentence-transformers` for local embeddings**
- **Fixes for API limits, mismatched dimensions, and deletion protection**
"""

# ‚úÖ Access secret keys securely in Google Colab
from google.colab import userdata

PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')
OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')

# Ensure keys are set before proceeding
assert PINECONE_API_KEY, "Pinecone API Key is missing!"
assert OPENAI_API_KEY, "OpenAI API Key is missing!"

import os
os.environ["PINECONE_API_KEY"] = PINECONE_API_KEY
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

print("‚úÖ API keys loaded securely!")

from pinecone import Pinecone

# ‚úÖ Initialize Pinecone client
pc = Pinecone(api_key=os.environ["PINECONE_API_KEY"])
index_name = "rag-pipeline-tutorial"

# ‚úÖ Disable deletion protection before recreating the index
try:
    pc.configure_index(index_name, deletion_protection="disabled")
    print(f"‚úÖ Deletion protection disabled for index: {index_name}")
except Exception as e:
    print(f"‚ö†Ô∏è Warning: Could not disable deletion protection. Index may not exist yet. {e}")

# ‚úÖ Delete existing index if it exists
existing_indexes = [index["name"] for index in pc.list_indexes()]
if index_name in existing_indexes:
    pc.delete_index(index_name)
    print(f"‚úÖ Index '{index_name}' deleted successfully.")
else:
    print(f"‚úÖ No existing index found. Proceeding to create a new one.")

# ‚úÖ Create a new Pinecone index with the correct dimension (384 for local embeddings)
from pinecone import ServerlessSpec

# ‚úÖ Create a new Pinecone index with the correct dimension (384 for local embeddings)
pc.create_index(
    name=index_name,
    dimension=384,  # Matches `all-MiniLM-L6-v2` model
    metric="euclidean",
    deletion_protection="enabled",  # Re-enable if needed
        spec=ServerlessSpec(  # Correcting the spec definition
        cloud="aws",
        region="us-east-1"
    )
)
print(f"‚úÖ New Pinecone index '{index_name}' created with dimension 384.")

from sentence_transformers import SentenceTransformer
from langchain_pinecone import PineconeVectorStore
from langchain.embeddings.base import Embeddings

# ‚úÖ Load a local embedding model (384D)
embeddings_model = SentenceTransformer("all-MiniLM-L6-v2")

# ‚úÖ Wrapper to ensure compatibility with LangChain
class LocalEmbeddings(Embeddings):
    def embed_documents(self, texts):
        return embeddings_model.encode(texts, convert_to_numpy=True).tolist()

    def embed_query(self, text):
        return embeddings_model.encode([text], convert_to_numpy=True).tolist()

embeddings = LocalEmbeddings()

print("‚úÖ Local embeddings model loaded successfully!")

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

# ‚úÖ Example documents (Replace with your actual dataset)
docs = [
    "Vector databases store high-dimensional vectors used for semantic search.",
    "Pinecone is a serverless vector database optimized for AI applications.",
    "Large Language Models (LLMs) use vector databases to improve retrieval accuracy."
]

# ‚úÖ Convert docs into a list of `Document` objects
documents = [Document(page_content=doc) for doc in docs]


# ‚úÖ Split documents into chunks
text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)
# ‚úÖ Use the correct method to split documents
split_docs = text_splitter.split_documents(documents)


print(f"‚úÖ Loaded and split {len(split_docs)} document chunks!")

# ‚úÖ Store document vectors in Pinecone
vectorstore = PineconeVectorStore.from_documents(split_docs, embeddings, index_name=index_name)
print("‚úÖ Documents successfully stored in Pinecone!")

# ‚úÖ Run a similarity search query
query = "What is a vector database?"
results = vectorstore.similarity_search(query)

# ‚úÖ Print retrieved results
for i, doc in enumerate(results):
    print(f"Result {i+1}: {doc.page_content}")

"""
## üöÄ **Next Enhancements**
1. **Improve retrieval quality** ‚Äì Fine-tune embeddings for domain-specific knowledge.
2. **Optimize query performance** ‚Äì Implement vector caching strategies.
3. **Enhance batch processing** ‚Äì Improve bulk vector updates in Pinecone.
4. **Implement Hybrid Search** ‚Äì Combine **Vector + Keyword Search** for better accuracy.
5. **Use Re-Ranking models** ‚Äì Apply `cross-encoder` to improve ranking.
6. **Expand Data Sources** ‚Äì Integrate a more diverse document set.
7. **Integrate a Chatbot** ‚Äì Build an AI chatbot using the Pinecone knowledge base.

üîπ This notebook **fully integrates fixes for API limits, mismatched dimensions, deletion protection, and retrieval optimizations**.  
üí° Feel free to experiment and extend the pipeline with the listed enhancements! üéØ  
"""

